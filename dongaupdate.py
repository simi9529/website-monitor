import json

STORAGE_PATH = "storage.json"

def load_last_titles():
    if os.path.exists(STORAGE_PATH):
        with open(STORAGE_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}

def save_last_titles(data):
    with open(STORAGE_PATH, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

import requests
from bs4 import BeautifulSoup
import smtplib
from email.mime.text import MIMEText
import schedule
import time
import os
from urllib.parse import urljoin
from dotenv import load_dotenv

load_dotenv()

FROM_EMAIL = os.environ.get("FROM_EMAIL")
TO_EMAIL = os.environ.get("TO_EMAIL")
APP_PASSWORD = os.environ.get("APP_PASSWORD")

sites = [
    {
        "name": "ë™ì•„ëŒ€ law í•™ì‚¬ê³µì§€",
        "url": "https://law.donga.ac.kr/law/CMS/Board/Board.do?mCode=MN056",
       "last_title": None,
        "selector": "table.bdListTbl td.subject a"
    },
    {
        "name": "ë™ì•„ëŒ€ law ìˆ˜ì—…ê³µì§€",
        "url": "https://law.donga.ac.kr/law/CMS/Board/Board.do?mCode=MN057",
        "last_title": None,
        "selector": "table.bdListTbl td.subject a"
    },
    {
        "name": "ë™ì•„ëŒ€ law íŠ¹ê°•ë° ëª¨ì˜ê³ ì‚¬",
        "url": "https://law.donga.ac.kr/law/CMS/Board/Board.do?mCode=MN059",
        "last_title": None,
        "selector": "table.bdListTbl td.subject a"
    }
]

def send_email(subject, body):
    msg = MIMEText(body)
    msg["Subject"] = subject
    msg["From"] = FROM_EMAIL
    msg["To"] = TO_EMAIL

    try:
        with smtplib.SMTP_SSL("smtp.gmail.com", 465) as server:
            server.login(FROM_EMAIL, APP_PASSWORD)
            server.send_message(msg)
            print(f"âœ… ì´ë©”ì¼ ë°œì†¡ ì™„ë£Œ: {subject}")
    except Exception as e:
        print(f"âŒ ì´ë©”ì¼ ë°œì†¡ ì‹¤íŒ¨: {e}")

def check_site(site):
    try:
        response = requests.get(site["url"])
        response.raise_for_status()
        soup = BeautifulSoup(response.text, "html.parser")
        post_tag = soup.select_one(site["selector"])

        if post_tag:
            title = post_tag.text.strip()
            href = post_tag.get('href', '')

            if site["last_title"] is None:
                site["last_title"] = title
                print(f"ğŸ“Œ [{site['name']}] ì²« ê°ì‹œ ì‹œì‘: {title}")
            elif title != site["last_title"]:
                print(f"ğŸ†• [{site['name']}] ìƒˆ ê¸€ ë°œê²¬: {title}")
                link = urljoin(site["url"], href)
                body = f"ìƒˆ ê¸€ì´ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤!\n\n[{site['name']}]\nì œëª©: {title}\në§í¬: {link}"
                send_email(f"[ìƒˆ ê¸€ ì•Œë¦¼] {site['name']}", body)
                site["last_title"] = title
            else:
                print(f"ğŸ” [{site['name']}] ë³€í™” ì—†ìŒ: {title}")
        else:
            print(f"âš ï¸ [{site['name']}] ê²Œì‹œê¸€ ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. selectorë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    except Exception as e:
        print(f"âŒ [{site['name']}] ì˜¤ë¥˜ ë°œìƒ: {e}")

def check_all_sites():
    last_titles = load_last_titles()

    for site in sites:
        site_name = site["name"]
        site["last_title"] = last_titles.get(site_name)
        check_site(site)
        # ì—…ë°ì´íŠ¸ëœ ì œëª© ì €ì¥
        last_titles[site_name] = site["last_title"]

    save_last_titles(last_titles)
    
def run_monitor():
    schedule.every(5).minutes.do(check_all_sites)
    print("ğŸ“¡ ì‚¬ì´íŠ¸ ê°ì‹œ ì‹œì‘ (5ë¶„ ê°„ê²©)")
    while True:
        schedule.run_pending()
        time.sleep(1)

if __name__ == "__main__":
    if os.environ.get("GITHUB_ACTIONS") == "true":
        # GitHub Actionsì—ì„œëŠ” ë”± í•œ ë²ˆ ì‹¤í–‰ í›„ ì¢…ë£Œ
        check_all_sites()
    else:
        # ë¡œì»¬ì—ì„œ ì‹¤í–‰í•  ë•ŒëŠ” ê°ì‹œ ë£¨í”„ ì§€ì†
        run_monitor()
