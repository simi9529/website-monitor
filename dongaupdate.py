import requests
from bs4 import BeautifulSoup
import smtplib
from email.mime.text import MIMEText
import os
import json
from urllib.parse import urljoin
from playwright.sync_api import sync_playwright

# =====================
# ì´ë©”ì¼ / ë¡œê·¸ì¸ ì •ë³´
# =====================
FROM_EMAIL = os.environ.get("FROM_EMAIL")
TO_EMAIL = os.environ.get("TO_EMAIL")
APP_PASSWORD = os.environ.get("APP_PASSWORD")
USER_ID = os.environ.get("USER_ID")
USER_PW = os.environ.get("USER_PW")

# ìƒíƒœ ì €ì¥ íŒŒì¼
STATE_FILE = "titles.json"

# =====================
# ì‚¬ì´íŠ¸ ì„¤ì •
# =====================
login_required_sites = [
    {
        "name": "ì´í™”ì´ì–¸ ììœ ê²Œì‹œíŒ",
        "url": "https://ewhaian.com/",
        "selector": "ul.contentList li.contentItem a"
    }
]

public_sites = [
    {
        "name": "ë™ì•„ëŒ€ law í•™ì‚¬ê³µì§€",
        "url": "https://law.donga.ac.kr/law/CMS/Board/Board.do?mCode=MN056",
        "selector": "table.bdListTbl td.subject a"
    },
    {
        "name": "ë™ì•„ëŒ€ law ìˆ˜ì—…ê³µì§€",
        "url": "https://law.donga.ac.kr/law/CMS/Board/Board.do?mCode=MN057",
        "selector": "table.bdListTbl td.subject a"
    },
    {
        "name": "ë™ì•„ëŒ€ law íŠ¹ê°•ë° ëª¨ì˜ê³ ì‚¬",
        "url": "https://law.donga.ac.kr/law/CMS/Board/Board.do?mCode=MN059",
        "selector": "table.bdListTbl td.subject a"
    }
]

# =====================
# ìœ í‹¸ í•¨ìˆ˜
# =====================
def load_titles():
    if os.path.exists(STATE_FILE):
        with open(STATE_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}

def save_titles(data):
    with open(STATE_FILE, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def send_email(subject, body):
    msg = MIMEText(body)
    msg["Subject"] = subject
    msg["From"] = FROM_EMAIL
    msg["To"] = TO_EMAIL

    try:
        with smtplib.SMTP_SSL("smtp.gmail.com", 465) as server:
            server.login(FROM_EMAIL, APP_PASSWORD)
            server.send_message(msg)
            print(f"âœ… ì´ë©”ì¼ ë°œì†¡: {subject}")
    except Exception as e:
        print(f"âŒ ì´ë©”ì¼ ë°œì†¡ ì‹¤íŒ¨: {e}")

def login(session, url, data):
    try:
        res = session.post(url, data=data)
        res.raise_for_status()
        print("âœ… ë¡œê·¸ì¸ ì„±ê³µ")
        return True
    except Exception as e:
        print(f"âŒ ë¡œê·¸ì¸ ì‹¤íŒ¨: {e}")
        return False

# =====================
# í•µì‹¬ ê°ì‹œ í•¨ìˆ˜
# =====================
def check_site(site, last_state, session=None):
    soup = None

    # --- ì´í™”ì´ì–¸ (Playwright) ---
    if session and site["name"] == "ì´í™”ì´ì–¸ ììœ ê²Œì‹œíŒ":
        try:
            with sync_playwright() as p:
                browser = p.chromium.launch(headless=True)
                context = browser.new_context()

                cookies = [
                    {"name": c.name, "value": c.value, "url": site["url"]}
                    for c in session.cookies
                ]
                context.add_cookies(cookies)

                page = context.new_page()
                page.goto(site["url"], wait_until="networkidle")
                page.wait_for_selector("ul.contentList", timeout=30000)

                soup = BeautifulSoup(page.content(), "html.parser")
                browser.close()

        except Exception as e:
            print(f"âŒ [{site['name']}] Playwright ì˜¤ë¥˜: {e}")
            return

    # --- ì¼ë°˜ ì‚¬ì´íŠ¸ (requests) ---
    else:
        try:
            res = session.get(site["url"]) if session else requests.get(site["url"])
            res.raise_for_status()
            soup = BeautifulSoup(res.text, "html.parser")
        except Exception as e:
            print(f"âŒ [{site['name']}] ì ‘ì† ì˜¤ë¥˜: {e}")
            return

    if soup is None:
        return

    # =====================
    # ê²Œì‹œê¸€ ë²ˆí˜¸(board_seq) ê¸°ì¤€ ê°ì§€
    # =====================
    post_tags = soup.select(site["selector"])

    latest_post_id = None
    latest_title = None
    latest_link = None

    for tag in post_tags:
        href = tag.get("href", "")
        if "board_seq=" in href:
            latest_post_id = href.split("board_seq=")[-1]
            latest_title = tag.text.strip()
            latest_link = urljoin(site["url"], href)
            break   # âœ… ì²« ë²ˆì§¸ ì¼ë°˜ê¸€ë§Œ ì‚¬ìš©

    if not latest_post_id:
        print(f"âš ï¸ [{site['name']}] board_seq ë¯¸ê²€ì¶œ")
        return

    last_id = last_state.get(site["name"])

    if last_id != latest_post_id:
        print(f"ğŸ†• [{site['name']}] ìƒˆ ê¸€ ê°ì§€")
        body = (
            f"ìƒˆ ê¸€ì´ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.\n\n"
            f"[{site['name']}]\n"
            f"ì œëª©: {latest_title}\n"
            f"ê¸€ ë²ˆí˜¸: {latest_post_id}\n"
            f"ë§í¬: {latest_link}"
        )
        send_email(f"[ìƒˆ ê¸€ ì•Œë¦¼] {site['name']}", body)
        last_state[site["name"]] = latest_post_id
    else:
        print(f"ğŸ” [{site['name']}] ë³€í™” ì—†ìŒ ({latest_post_id})")

# =====================
# ì „ì²´ ì‹¤í–‰
# =====================
def check_all_sites(session):
    last_state = load_titles()

    if session:
        for site in login_required_sites:
            check_site(site, last_state, session)

    for site in public_sites:
        check_site(site, last_state)

    save_titles(last_state)

if __name__ == "__main__":
    login_url = "https://ewhaian.com/login"
    login_data = {
        "username": USER_ID,
        "password": USER_PW
    }

    with requests.Session() as session:
        if login(session, login_url, login_data):
            check_all_sites(session)
        else:
            check_all_sites(None)
